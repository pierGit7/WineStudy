{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the raw data\n",
    "fp = \"/Users/gloriastucchi/Desktop/introtoml/project2/WineStudy/wine_data_fixed.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "# df standardise:\n",
    "df = (df - df.mean()) / df.std()\n",
    "\n",
    "\n",
    "y = df['Alcohol'].values\n",
    "df = df.drop(columns=['Alcohol'])\n",
    "\n",
    "#X = df.drop(columns=['Alcohol'])\n",
    "X = df\n",
    "X = X.values\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "# Headings\n",
    "attributeNames = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib_resources\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pyplot import clim, figure, plot, show, subplot, title, xlabel, ylabel\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "\n",
    "from dtuimldmtools import bmplot, feature_selector_lr\n",
    "\n",
    "#filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/body.mat\")\n",
    "# Load data from matlab file\n",
    "#mat_data = loadmat(filename)\n",
    "\n",
    "#X = mat_data['X']\n",
    "#y = mat_data['y'].squeeze()\n",
    "\n",
    "print(\"X dataset\", X.shape)\n",
    "print(\"y dataset\", y.shape)\n",
    "\n",
    "#attributeNames = [name[0] for name in mat_data['attributeNames'][0]]\n",
    "N, M = X.shape\n",
    "\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 5\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True)\n",
    "\n",
    "# Initialize variables\n",
    "Features = np.zeros((M,K))\n",
    "Error_train = np.empty((K,1))\n",
    "Error_test = np.empty((K,1))\n",
    "Error_train_fs = np.empty((K,1))\n",
    "Error_test_fs = np.empty((K,1))\n",
    "Error_train_nofeatures = np.empty((K,1))\n",
    "Error_test_nofeatures = np.empty((K,1))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "    \n",
    "    # Compute squared error without using the input data at all\n",
    "    Error_train_nofeatures[k] = np.square(y_train-y_train.mean()).sum()/y_train.shape[0]\n",
    "    Error_test_nofeatures[k] = np.square(y_test-y_test.mean()).sum()/y_test.shape[0]\n",
    "\n",
    "    # Compute squared error with all features selected (no feature selection)\n",
    "    m = lm.LinearRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "    Error_train[k] = np.square(y_train-m.predict(X_train)).sum()/y_train.shape[0]\n",
    "    Error_test[k] = np.square(y_test-m.predict(X_test)).sum()/y_test.shape[0]\n",
    "\n",
    "    # Compute squared error with feature subset selection\n",
    "    textout = ''\n",
    "    selected_features, features_record, loss_record = feature_selector_lr(X_train, y_train, internal_cross_validation,display=textout)\n",
    "    \n",
    "    Features[selected_features,k] = 1\n",
    "    # .. alternatively you could use module sklearn.feature_selection\n",
    "    if len(selected_features) == 0:\n",
    "        print('No features were selected, i.e. the data (X) in the fold cannot describe the outcomes (y).' )\n",
    "    else:\n",
    "        m = lm.LinearRegression(fit_intercept=True).fit(X_train[:,selected_features], y_train)\n",
    "        Error_train_fs[k] = np.square(y_train-m.predict(X_train[:,selected_features])).sum()/y_train.shape[0]\n",
    "        Error_test_fs[k] = np.square(y_test-m.predict(X_test[:,selected_features])).sum()/y_test.shape[0]\n",
    "    \n",
    "        figure(k)\n",
    "        subplot(1,2,1)\n",
    "        plot(range(1,len(loss_record)), loss_record[1:])\n",
    "        xlabel('Iteration')\n",
    "        ylabel('Squared error (crossvalidation)')    \n",
    "        \n",
    "        subplot(1,3,3)\n",
    "        bmplot(attributeNames, range(1,features_record.shape[1]), -features_record[:,1:])\n",
    "        clim(-1.5,0)\n",
    "        xlabel('Iteration')\n",
    "\n",
    "    print('Cross validation fold {0}/{1}'.format(k+1,K))\n",
    "    print('Train indices: {0}'.format(train_index))\n",
    "    print('Test indices: {0}'.format(test_index))\n",
    "    print('Features no: {0}\\n'.format(selected_features.size))\n",
    "\n",
    "    k+=1\n",
    "\n",
    "\n",
    "# Display results\n",
    "print('\\n')\n",
    "print('Linear regression without feature selection:\\n')\n",
    "print('- Training error: {0}'.format(Error_train.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}'.format((Error_test_nofeatures.sum()-Error_test.sum())/Error_test_nofeatures.sum()))\n",
    "print('Linear regression with feature selection:\\n')\n",
    "print('- Training error: {0}'.format(Error_train_fs.mean()))\n",
    "print('- Test error:     {0}'.format(Error_test_fs.mean()))\n",
    "print('- R^2 train:     {0}'.format((Error_train_nofeatures.sum()-Error_train_fs.sum())/Error_train_nofeatures.sum()))\n",
    "print('- R^2 test:     {0}'.format((Error_test_nofeatures.sum()-Error_test_fs.sum())/Error_test_nofeatures.sum()))\n",
    "\n",
    "figure(k)\n",
    "subplot(1,3,2)\n",
    "bmplot(attributeNames, range(1,Features.shape[1]+1), -Features)\n",
    "clim(-1.5,0)\n",
    "xlabel('Crossvalidation fold')\n",
    "ylabel('Attribute')\n",
    "\n",
    "\n",
    "# Inspect selected feature coefficients effect on the entire dataset and\n",
    "# plot the fitted model residual error as function of each attribute to\n",
    "# inspect for systematic structure in the residual\n",
    "\n",
    "f=2 # cross-validation fold to inspect\n",
    "ff=Features[:,f-1].nonzero()[0]\n",
    "if len(ff) == 0:\n",
    "    print('\\nNo features were selected, i.e. the data (X) in the fold cannot describe the outcomes (y).' )\n",
    "else:\n",
    "    m = lm.LinearRegression(fit_intercept=True).fit(X[:,ff], y)\n",
    "    \n",
    "    y_est= m.predict(X[:,ff])\n",
    "    residual=y-y_est\n",
    "    \n",
    "    figure(k+1, figsize=(12,6))\n",
    "    title('Residual error vs. Attributes for features selected in cross-validation fold {0}'.format(f))\n",
    "    for i in range(0,len(ff)):\n",
    "       subplot(2, int( np.ceil(len(ff)/2)), i+1)\n",
    "       plot(X[:,ff[i]],residual,'.')\n",
    "       xlabel(attributeNames[ff[i]])\n",
    "       ylabel('residual error')\n",
    "    \n",
    "    \n",
    "show()\n",
    "\n",
    "print('Ran Exercise 6.2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotGenErr(testErr, k, lambdas):\n",
    "    genErr = testErr * 1/k\n",
    "    figure(k, figsize=(12,8))\n",
    "    plot(genErr, lambdas)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 8.1.1\n",
    "\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import (\n",
    "    figure,\n",
    "    grid,\n",
    "    legend,\n",
    "    loglog,\n",
    "    semilogx,\n",
    "    show,\n",
    "    subplot,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    ")\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "\n",
    "from dtuimldmtools import rlr_validate\n",
    "\n",
    "#filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/body.mat\")\n",
    "\n",
    "\n",
    "#mat_data = loadmat(filename)\n",
    "#X = mat_data[\"X\"]\n",
    "#y = mat_data[\"y\"].squeeze()\n",
    "#attributeNames = [name[0] for name in mat_data[\"attributeNames\"][0]]\n",
    "N, M = X.shape\n",
    "\n",
    "# Add offset attribute\n",
    "X = np.concatenate((np.ones((X.shape[0], 1)), X), 1)\n",
    "attributeNames = [\"Offset\"] + attributeNames\n",
    "M = M + 1\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 5\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "# CV = model_selection.KFold(K, shuffle=False)\n",
    "\n",
    "# Values of lambda\n",
    "lambdas = np.power(10.0, range(-5, 9))\n",
    "\n",
    "# Initialize variables\n",
    "# T = len(lambdas)\n",
    "Error_train = np.empty((K, 1))\n",
    "Error_test = np.empty((K, 1))\n",
    "Error_train_rlr = np.empty((K, 1))\n",
    "Error_test_rlr = np.empty((K, 1))\n",
    "Error_train_nofeatures = np.empty((K, 1))\n",
    "Error_test_nofeatures = np.empty((K, 1))\n",
    "w_rlr = np.empty((M, K))\n",
    "mu = np.empty((K, M - 1))\n",
    "sigma = np.empty((K, M - 1))\n",
    "w_noreg = np.empty((M, K))\n",
    "\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "\n",
    "    (\n",
    "        opt_val_err,\n",
    "        opt_lambda,\n",
    "        mean_w_vs_lambda,\n",
    "        train_err_vs_lambda,\n",
    "        test_err_vs_lambda,\n",
    "    ) = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "\n",
    "    # Standardize outer fold based on training set, and save the mean and standard\n",
    "    # deviations since they're part of the model (they would be needed for\n",
    "    # making new predictions) - for brevity we won't always store these in the scripts\n",
    "    mu[k, :] = np.mean(X_train[:, 1:], 0)\n",
    "    sigma[k, :] = np.std(X_train[:, 1:], 0)\n",
    "\n",
    "    X_train[:, 1:] = (X_train[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "    X_test[:, 1:] = (X_test[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "\n",
    "    Xty = X_train.T @ y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "\n",
    "    # Compute mean squared error without using the input data at all\n",
    "    Error_train_nofeatures[k] = (\n",
    "        np.square(y_train - y_train.mean()).sum(axis=0) / y_train.shape[0]\n",
    "    )\n",
    "    Error_test_nofeatures[k] = (\n",
    "        np.square(y_test - y_test.mean()).sum(axis=0) / y_test.shape[0]\n",
    "    )\n",
    "\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(M)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    w_rlr[:, k] = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "\n",
    "    # Compute mean squared error with regularization with optimal lambda\n",
    "    Error_train_rlr[k] = (\n",
    "        np.square(y_train - X_train @ w_rlr[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "    )\n",
    "    Error_test_rlr[k] = (\n",
    "        np.square(y_test - X_test @ w_rlr[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "    )\n",
    "\n",
    "    # Estimate weights for unregularized linear regression, on entire training set\n",
    "    w_noreg[:, k] = np.linalg.solve(XtX, Xty).squeeze()\n",
    "    # Compute mean squared error without regularization\n",
    "    Error_train[k] = (\n",
    "        np.square(y_train - X_train @ w_noreg[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "    )\n",
    "    Error_test[k] = (\n",
    "        np.square(y_test - X_test @ w_noreg[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "    )\n",
    "    # OR ALTERNATIVELY: you can use sklearn.linear_model module for linear regression:\n",
    "    # m = lm.LinearRegression().fit(X_train, y_train)\n",
    "    # Error_train[k] = np.square(y_train-m.predict(X_train)).sum()/y_train.shape[0]\n",
    "    # Error_test[k] = np.square(y_test-m.predict(X_test)).sum()/y_test.shape[0]\n",
    "\n",
    "    # Display the results for the last cross-validation fold\n",
    "    if k == K - 1:\n",
    "        figure(k, figsize=(12, 8))\n",
    "        subplot(1, 2, 1)\n",
    "        semilogx(lambdas, mean_w_vs_lambda.T[:, 1:], \".-\")  # Don't plot the bias term\n",
    "        xlabel(\"Regularization factor\")\n",
    "        ylabel(\"Mean Coefficient Values\")\n",
    "        grid()\n",
    "        # You can choose to display the legend, but it's omitted for a cleaner\n",
    "        # plot, since there are many attributes\n",
    "        # legend(attributeNames[1:], loc='best')\n",
    "\n",
    "        subplot(1, 2, 2)\n",
    "        title(\"Optimal lambda: 1e{0}\".format(np.log10(opt_lambda)))\n",
    "        loglog(\n",
    "            lambdas, train_err_vs_lambda.T, \"b.-\", lambdas, test_err_vs_lambda.T, \"r.-\"\n",
    "        )\n",
    "        xlabel(\"Regularization factor\")\n",
    "        ylabel(\"Squared error (crossvalidation)\")\n",
    "        legend([\"Train error\", \"Validation error\"])\n",
    "        grid()\n",
    "\n",
    "        #PlotGenErr(test_err_vs_lambda, k, lambdas)\n",
    "\n",
    "\n",
    "    # To inspect the used indices, use these print statements\n",
    "    # print('Cross validation fold {0}/{1}:'.format(k+1,K))\n",
    "    # print('Train indices: {0}'.format(train_index))\n",
    "    # print('Test indices: {0}\\n'.format(test_index))\n",
    "\n",
    "    k += 1\n",
    "\n",
    "show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(\"Linear regression without feature selection:\")\n",
    "print(\"- Training error: {0}\".format(Error_train.mean()))\n",
    "print(\"- Test error:     {0}\".format(Error_test.mean()))\n",
    "print(\n",
    "    \"- R^2 train:     {0}\".format(\n",
    "        (Error_train_nofeatures.sum() - Error_train.sum())\n",
    "        / Error_train_nofeatures.sum()\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"- R^2 test:     {0}\\n\".format(\n",
    "        (Error_test_nofeatures.sum() - Error_test.sum()) / Error_test_nofeatures.sum()\n",
    "    )\n",
    ")\n",
    "print(\"Regularized linear regression:\")\n",
    "print(\"- Training error: {0}\".format(Error_train_rlr.mean()))\n",
    "print(\"- Test error:     {0}\".format(Error_test_rlr.mean()))\n",
    "print(\n",
    "    \"- R^2 train:     {0}\".format(\n",
    "        (Error_train_nofeatures.sum() - Error_train_rlr.sum())\n",
    "        / Error_train_nofeatures.sum()\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"- R^2 test:     {0}\\n\".format(\n",
    "        (Error_test_nofeatures.sum() - Error_test_rlr.sum())\n",
    "        / Error_test_nofeatures.sum()\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Weights in last fold:\")\n",
    "for m in range(M):\n",
    "    print(\"{:>15} {:>15}\".format(attributeNames[m], np.round(w_rlr[m, -1], 2)))\n",
    "\n",
    "print(\"Ran Exercise 8.1.1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain the splits so that we can re-run the models on the same data\n",
    "K = 5  \n",
    "CV = model_selection.KFold(K, shuffle=True, random_state=123)\n",
    "splits = list(CV.split(X, y)) #list because the generator can be exhausted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 8.2.6\n",
    "import importlib_resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "\n",
    "from dtuimldmtools import draw_neural_net, train_neural_net\n",
    "\n",
    "N, M = X.shape\n",
    "C = 2\n",
    "\n",
    "# Normalize data\n",
    "X = stats.zscore(X)\n",
    "\n",
    "## Normalize and compute PCA (change to True to experiment with PCA preprocessing)\n",
    "do_pca_preprocessing = False\n",
    "if do_pca_preprocessing:\n",
    "    Y = stats.zscore(X, 0)\n",
    "    U, S, V = np.linalg.svd(Y, full_matrices=False)\n",
    "    V = V.T\n",
    "    # Components to be included as features\n",
    "    k_pca = 3\n",
    "    X = X @ V[:, :k_pca]\n",
    "    N, M = X.shape\n",
    "\n",
    "\n",
    "# Parameters for neural network classifier\n",
    "n_hidden_units = 20  # number of hidden units\n",
    "n_replicates = 1  # number of networks trained in each k-fold\n",
    "max_iter = 10000\n",
    "\n",
    "# K-fold crossvalidation\n",
    "#K = 5  # only three folds to speed up this example\n",
    "#CV = model_selection.KFold(K, shuffle=True, random_state=123)\n",
    "\n",
    "# Setup figure for display of learning curves and error rates in fold\n",
    "summaries, summaries_axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# Make a list for storing assigned color of learning curve for up to K=10\n",
    "color_list = [\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "    \"tab:red\",\n",
    "    \"tab:blue\",\n",
    "]\n",
    "# Define the model\n",
    "model = lambda: torch.nn.Sequential(\n",
    "    torch.nn.Linear(M, n_hidden_units),  # M features to n_hidden_units\n",
    "    torch.nn.Tanh(),  # 1st transfer function,\n",
    "    torch.nn.Linear(n_hidden_units, 1),  # n_hidden_units to 1 output neuron\n",
    "    # no final tranfer function, i.e. \"linear output\"\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()  # notice how this is now a mean-squared-error loss\n",
    "\n",
    "print(\"Training model of type:\\n\\n{}\\n\".format(str(model())))\n",
    "errors = []  # make a list for storing generalizaition error in each loop\n",
    "for k, (train_index, test_index) in enumerate(splits):\n",
    "    print(\"\\nCrossvalidation fold: {0}/{1}\".format(k + 1, K))\n",
    "\n",
    "    # Extract training and test set for current CV fold, convert to tensors\n",
    "    X_train = torch.Tensor(X[train_index, :])\n",
    "    y_train = torch.Tensor(y[train_index])\n",
    "    X_test = torch.Tensor(X[test_index, :])\n",
    "    y_test = torch.Tensor(y[test_index])\n",
    "\n",
    "    # Train the net on training data\n",
    "    net, final_loss, learning_curve = train_neural_net(\n",
    "        model,\n",
    "        loss_fn,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        n_replicates=n_replicates,\n",
    "        max_iter=max_iter,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\tBest loss: {}\\n\".format(final_loss))\n",
    "\n",
    "    # Determine estimated class labels for test set\n",
    "    y_test_est = net(X_test)\n",
    "\n",
    "    # Determine errors and errors\n",
    "    se = (y_test_est.float() - y_test.float()) ** 2  # squared error\n",
    "    mse = (sum(se).type(torch.float) / len(y_test)).data.numpy()  # mean\n",
    "    errors.append(mse)  # store error rate for current CV fold\n",
    "\n",
    "    # Display the learning curve for the best net in the current fold\n",
    "    (h,) = summaries_axes[0].plot(learning_curve, color=color_list[k])\n",
    "    h.set_label(\"CV fold {0}\".format(k + 1))\n",
    "    summaries_axes[0].set_xlabel(\"Iterations\")\n",
    "    summaries_axes[0].set_xlim((0, max_iter))\n",
    "    summaries_axes[0].set_ylabel(\"Loss\")\n",
    "    summaries_axes[0].set_title(\"Learning curves\")\n",
    "\n",
    "# Display the MSE across folds\n",
    "summaries_axes[1].bar(\n",
    "    np.arange(1, K + 1), np.squeeze(np.asarray(errors)), color=color_list\n",
    ")\n",
    "summaries_axes[1].set_xlabel(\"Fold\")\n",
    "summaries_axes[1].set_xticks(np.arange(1, K + 1))\n",
    "summaries_axes[1].set_ylabel(\"MSE\")\n",
    "summaries_axes[1].set_title(\"Test mean-squared-error\")\n",
    "\n",
    "print(\"Diagram of best neural net in last fold:\")\n",
    "weights = [net[i].weight.data.numpy().T for i in [0, 2]]\n",
    "biases = [net[i].bias.data.numpy() for i in [0, 2]]\n",
    "tf = [str(net[i]) for i in [1, 2]]\n",
    "draw_neural_net(weights, biases, tf, attribute_names=attributeNames)\n",
    "\n",
    "# Print the average classification error rate\n",
    "print(\n",
    "    \"\\nEstimated generalization error, RMSE: {0}\".format(\n",
    "        round(np.sqrt(np.mean(errors)), 4)\n",
    "    )\n",
    ")\n",
    "\n",
    "# When dealing with regression outputs, a simple way of looking at the quality\n",
    "# of predictions visually is by plotting the estimated value as a function of\n",
    "# the true/known value - these values should all be along a straight line \"y=x\",\n",
    "# and if the points are above the line, the model overestimates, whereas if the\n",
    "# points are below the y=x line, then the model underestimates the value\n",
    "plt.figure(figsize=(10, 10))\n",
    "y_est = y_test_est.data.numpy()\n",
    "y_true = y_test.data.numpy()\n",
    "axis_range = [np.min([y_est, y_true]) - 1, np.max([y_est, y_true]) + 1]\n",
    "plt.plot(axis_range, axis_range, \"k--\")\n",
    "plt.plot(y_true, y_est, \"ob\", alpha=0.25)\n",
    "plt.legend([\"Perfect estimation\", \"Model estimations\"])\n",
    "plt.title(\"Alcohol content: estimated versus true value (for last CV-fold)\")\n",
    "plt.ylim(axis_range)\n",
    "plt.xlim(axis_range)\n",
    "plt.xlabel(\"True value\")\n",
    "plt.ylabel(\"Estimated value\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Ran Exercise 8.2.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hidden units for outer fold 1: 2\n",
      "\n",
      "Selected hidden units for outer fold 2: 10\n",
      "\n",
      "Selected hidden units for outer fold 3: 5\n",
      "\n",
      "Selected hidden units for outer fold 4: 5\n",
      "\n",
      "Selected hidden units for outer fold 5: 2\n",
      "\n",
      "\n",
      "Two-level cross-validation table:\n",
      " Outer fold  ANN Hidden Units  ANN Accuracy  Logistic Regression (λ*)  Logistic Accuracy  Baseline Accuracy\n",
      "          1                 2        0.9167                        10             0.8889             0.3889\n",
      "          2                10        0.9722                        10             1.0000             0.3889\n",
      "          3                 5        0.9714                         5             0.9714             0.4571\n",
      "          4                 5        1.0000                        10             0.9714             0.3714\n",
      "          5                 2        1.0000                        10             1.0000             0.4000\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from dtuimldmtools import rlr_validate  # Assuming this is the correct import\n",
    "\n",
    "# Load dataset function\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    y = data.iloc[1:, 0] - 1  # Adjust labels to be zero-indexed for PyTorch\n",
    "    X = data.iloc[1:, 1:]\n",
    "    return X.values, y.values\n",
    "\n",
    "# Function for ANN classifier\n",
    "class ANNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_units, num_classes):\n",
    "        super(ANNClassifier, self).__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_units)\n",
    "        self.output = nn.Linear(hidden_units, num_classes)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Function to train ANN\n",
    "def train_ann(X_train, y_train, X_val, hidden_units=20, max_iter=2000):\n",
    "    input_dim = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    model = ANNClassifier(input_dim, hidden_units, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "\n",
    "    for epoch in range(max_iter):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_val = model(X_val_tensor)\n",
    "        _, predictions = torch.max(outputs_val, 1)\n",
    "    return predictions.numpy()\n",
    "\n",
    "# Baseline method\n",
    "def baseline_method(y_train, y_test):\n",
    "    most_common_class = Counter(y_train).most_common(1)[0][0]\n",
    "    predictions = np.full_like(y_test, most_common_class)\n",
    "    return predictions\n",
    "\n",
    "# Load the data\n",
    "filepath = \"/Users/gloriastucchi/Desktop/introtoml/project2/WineStudy/raw_data/wine.csv\"\n",
    "X, y = load_data(filepath)\n",
    "# Normalize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define cross-validation parameters\n",
    "K1 = 3  # Outer folds\n",
    "K2 = 3  # Inner folds\n",
    "kf_outer = KFold(n_splits=K1, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the set of discrete lambda values\n",
    "lambdas = np.array([1, 2, 5, 10])  # Fixed discrete set\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "# Outer cross-validation loop\n",
    "for outer_fold, (train_index, test_index) in enumerate(kf_outer.split(X), start=1):\n",
    "    X_outer_train, X_outer_test = X[train_index], X[test_index]\n",
    "    y_outer_train, y_outer_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Inner cross-validation for Logistic Regression using rlr_validate\n",
    "    internal_cv = K2\n",
    "    opt_val_err, best_lambda, _, _, _ = rlr_validate(X_outer_train, y_outer_train, lambdas, internal_cv)\n",
    "\n",
    "    # Ensure best_lambda is chosen strictly from the predefined lambdas\n",
    "    assert best_lambda in lambdas, f\"Unexpected λ value: {best_lambda}\"\n",
    "\n",
    "    # Train Logistic Regression on outer fold with best lambda\n",
    "    logreg_model = LogisticRegression(C=1/best_lambda, max_iter=1000, multi_class='multinomial')\n",
    "    logreg_model.fit(X_outer_train, y_outer_train)\n",
    "    logreg_pred = logreg_model.predict(X_outer_test)\n",
    "    logreg_acc = accuracy_score(y_outer_test, logreg_pred)\n",
    "\n",
    "    # Inner cross-validation for ANN\n",
    "    hidden_units_values = [1,2,5,10,25,50]\n",
    "    best_ann_acc = 0\n",
    "    best_hidden_units = None\n",
    "\n",
    "    for hidden_units in hidden_units_values:\n",
    "        inner_acc = []\n",
    "        for train_idx, val_idx in KFold(n_splits=K2, shuffle=True, random_state=42).split(X_outer_train):\n",
    "            X_train, X_val = X_outer_train[train_idx], X_outer_train[val_idx]\n",
    "            y_train, y_val = y_outer_train[train_idx], y_outer_train[val_idx]\n",
    "\n",
    "            ann_pred = train_ann(X_train, y_train, X_val, hidden_units=hidden_units)\n",
    "            val_acc = accuracy_score(y_val, ann_pred)\n",
    "            inner_acc.append(val_acc)\n",
    "\n",
    "        mean_acc = np.mean(inner_acc)\n",
    "        if mean_acc > best_ann_acc:\n",
    "            best_ann_acc = mean_acc\n",
    "            best_hidden_units = hidden_units\n",
    "\n",
    "    print(f\"Selected hidden units for outer fold {outer_fold}: {best_hidden_units}\\n\")\n",
    "\n",
    "    # Train final ANN with the best hyperparameters\n",
    "    ann_pred = train_ann(X_outer_train, y_outer_train, X_outer_test, hidden_units=best_hidden_units)\n",
    "    ann_acc = accuracy_score(y_outer_test, ann_pred)\n",
    "\n",
    "    # Baseline model\n",
    "    baseline_pred = baseline_method(y_outer_train, y_outer_test)\n",
    "    baseline_acc = accuracy_score(y_outer_test, baseline_pred)\n",
    "\n",
    "    # Store results\n",
    "    results_summary.append({\n",
    "        'Outer fold': outer_fold,\n",
    "        'ANN Hidden Units': best_hidden_units,\n",
    "        'ANN Accuracy': round(ann_acc, 4),\n",
    "        'Logistic Regression (λ*)': best_lambda,\n",
    "        'Logistic Accuracy': round(logreg_acc, 4),\n",
    "        'Baseline Accuracy': round(baseline_acc, 4)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and print\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\nTwo-level cross-validation table:\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introtoml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
